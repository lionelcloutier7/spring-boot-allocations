Laptop results:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.305 ± 0.162   s/op
MainBenchmark.shared      ss   10  0.257 ± 0.094   s/op
```

* "demo" creates a new class loader per application context (so all
the Spring metadata has to be read again because caches get cleared).
* "shared" means the same class loader for all contexts. In principal
this is as fast as we can ever go (things will always be a bit slower
because classes have to be loaded).

Without `spring.components`:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.331 ± 0.145   s/op
MainBenchmark.shared      ss   10  0.290 ± 0.072   s/op
```

The error bars are large, but there may be a small difference that is
worth keeping, even from such a minor change.

With `LazyInitBeanFactoryPostProcessor` (quite a useful boost):

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.197 ± 0.188   s/op
MainBenchmark.shared      ss   10  0.226 ± 0.067   s/op
```

=== Desktop Results

Vanilla:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  0.768 ± 0.110   s/op
MainBenchmark.shared      ss   10  0.159 ± 0.048   s/op
```

and with `LazyInitBeanFactoryPostProcessor`:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  0.696 ± 0.068   s/op
MainBenchmark.shared      ss   10  0.131 ± 0.024   s/op
```

== GC Data

Run the app with `-verbose:gc -XX:+PrintGCDetails
-XX:+PrintGCTimeStamps` to see GC pauses. E.g.

```
1.595: [Full GC (System.gc()) [PSYoungGen: 2080K->0K(23552K)] [ParOldGen: 11028K->11106K(55296K)] 13109K->11106K(78848K), [Metaspace: 23083K->23083K(1071104K)], 0.0511875 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
```

Total time 200ms.

== Flame Graphs

Download the https://github.com/jvm-profiling-tools/async-profiler[profiler] and run the app with these arguments:

```
-agentpath:<path-to>/async-profiler/build/libasyncProfiler.so=start,svg,file=/tmp/flame.svg,event=cpu,interval=100000 -Ddemo.close=true -Xmx128m -noverify -XX:TieredStopAtLevel=1
```

> HINT: you can click on the flames to zoom in on the stack above
> where you click.

[cols="50a,50a"]
|===
|image::images/flame_vanilla.svg[thread]
|image::images/flame_lazee.svg[lazy]

| Vanilla demo app
| Same but with the `LazyInitBeanFactoryPostProcessor`
|===

Notice the different (thinner) profile for the right hand "rump"
containing `ConfigurationClassPostProcessor`.

There is a `MicroApplication` (no `@Configuration` and no Spring Boot)
that starts up very quickly. Here's a flame graph:

image::images/flame_micro.svg[cpu,width=50%]

Note that there is very little time spent on garbage collection, and
of course nothing from `ConfigurationClassPostProcessor`.

== Ideas

* Up to now the strategy has been "use ASM and cache like crazy, run
everything dynamically". What about precomputing all that stuff?

* `@ComponentScan` -> `spring.components` and it seems to make very
little difference (but every little helps).

* What about `@Import`? A large fraction of configuration class
processing is taken up with `@Import`.

* `BeanInfoFactory` isn't a big footprint on the flame graphs, but
it's not minute either.

* `ConfigurationClassPostProcessor` does a lot of imports and metadata
reading. It always shows up in the flame graphs.

* CGLib: might not be slow at all actually, but it comes in for some
stick generally. Worth a look.

* Webflux is the other big hog in the simple demo application, after
`@Configuration` (Netty itself is relatively fast). Maybe that can be
streamlined as well?

Sifting through some flame graphs and other hints and data points, we
came to the conclusion that there are maybe 3 areas that are worth
some more research:

* `ConfigurationClassPostProcessor` is definitely up there and you can
quite easily change the `MetadataReaderFactory` it uses (Spring Boot
already boosts performance that way). We tried to serialize the
metadata, but the existing implementation is not serializable and
cannot easily be made so. There are some concerns about the fragility
of the annotation metadata implementations that are in use already
(one is ASM based and the other needs classes to be loaded). We need
the ASM-generated data for `ConfigurationClassPostProcessor`.

* CGLib *is* a bit slow, compared to vanilla reflective access. So
replacing the proxies in `@Configuration` processing might be a good
idea. Phil had some code that did this but he thought it didn't make
enough difference to continue (see
https://github.com/philwebb/spring-framework/tree/config-processor[here]).

* Bean creation is expensive still. `BeanWrapper` and `BeanInfo` are
right in the centre of that. There is a `BeanInfo` implementation in
this project (from Phil again) but it doesn't have any measurable
effect. Something else might work. The place to start looking is
`AbstractAutowireCapableBeanFactory` where the `doCreateBean()` method
could be replaced.

* Also Spring Boot condition messages create strings and concatenate
them even if they might never be used. this shows up a GC churn.

* `AnnotationTypeFilter` looks like another potential
optimization. It's >1% of startup time in the fastest app, and all it
needs to know is "Does `@Component` have `@Inherited`?" it seems.

* `MimeTypeUtils` has a `SecureRandom` and it is used by WebFlux to
initialize a codec, which is pretty fundamental, but takes 1.4% of
startup time in the fastest app. Setting
`-Djava.security.egd=file:/dev/./urandom` doesn't help.

* `DispatcherHandler` eagerly initializes a bunch of stuff (handler
mappings etc.) which is the biggest part of the WebFlux startup
flame. It doesn't seem to help much to make it lazy though - the flame
goes away but startup time is not improved.

* `ConfigFileApplicationListener` (5.5%) and
`LoggingApplicationListener` (2.2%) are two big differences between
the non-Boot and Boot samples.

== Hacking AbstractAutowireCapableBeanFactory

See https://jira.spring.io/browse/SPR-16918[SPR-16918]. This little hack:

```java
//            PropertyDescriptor[] filteredPds = filterPropertyDescriptorsForDependencyCheck(
//                    bw, mbd.allowCaching);
            PropertyDescriptor[] filteredPds = new PropertyDescriptor[0];
```

makes things really zippy:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.234 ± 0.195   s/op
MainBenchmark.boot        ss   10  1.145 ± 0.192   s/op
MainBenchmark.shared      ss   10  0.227 ± 0.070   s/op
```

With that change and some other minor tweaks (see below), you can run
the vanilla `DemoApplication` in 8m of heap (it starts a bit slowly
but runs fine). With 12m heap you see a lot more GC logged, but it
isn't much slower.

== Functional Bean Registration

Getting rid of as much `@Configuration` as possible would give us a
way to measure the effect of any inefficiencies in that area more
precisely. Here are some results:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.156 ± 0.203   s/op
MainBenchmark.boot        ss   10  1.115 ± 0.210   s/op
MainBenchmark.manual      ss   10  1.068 ± 0.185   s/op
MainBenchmark.bunc        ss   10  0.683 ± 0.147   s/op
MainBenchmark.func        ss   10  0.573 ± 0.149   s/op
MainBenchmark.shared      ss   10  0.219 ± 0.070   s/op
```

* "demo" is the canonical `DemoApplication` with `@SpringBootApplication`.

* "boot" uses `SpringApplication` but not
`@EnableAutoConfiguration`. It is a bit quicker (40ms or 4%). The
flame graph for this one has much less GC activity.

* "manual" is the same but gets rid of `SpringApplication`. Another
50ms improvement.

* "bunc" registers all beans in the application directly, by class or
using the functional bean registration API. It uses
`SpringApplication` (so all of Boot except autoconfig, basically).

* "func" creates the application context by hand, forgoing the
benefits of Spring Boot. Results are pretty good (first sample under
1000ms).

Some of the `@Configuration` beans are hard to use without registering
them as beans
(e.g. `WebFluxAutoConfiguration.EnableWebFluxConfiguration`). If you
do register a `@Configuration` manually (not using `@Import` or
`@ComponentScan`) there is still some post processing and reflective
calling of `@Bean` methods etc., but the CGLib proxy is skipped (might
have side effects, so probably not a good idea in general).

Here's a flame graph from the "func" sample:

image::images/flame_func.svg[func,width=50%]

Note that `ConfigurationClassPostProcessor` is not used at all. If it
was it would still account for 6% of the startup time because it
inspects every bean in the context, even though there we know there
are no `@Configuration` classes. To achieve this extra optimization
the user has to ensure that the application context is not one of the
annotation register implementations
(e.g. `ReactiveWebServerApplicationContext` instead of
`AnnotationConfigReactiveWebServerApplicationContext`) but also that
it does register an `AutowiredAnnotationBeanPostProcessor`.

The biggest flame on the "func" app graph was
`@ConfigurationProperties` processing (9%), but most of that was
initializing the conversion service, which is done in a background
thread in a Boot app. The timing shown above puts it in a background
thread (saving about 50ms).

We suspect that the difference between "demo" (vanilla) and "boot"
is condition processing, and that string manipulation can be removed
or optimized in Boot to reduce or eliminate that. Attempting to
collect evidence for this has so far failed. E.g. using this
https://github.com/wilkinsona/spring-boot/tree/empty-condition-messages[branch
of Spring Boot] didn't have much impact on any but the "boot" sample
(it should have improved the "demo" sample as much or more).

The biggest flame in the "boot" graph that isn't in the "manual" one
is from `BackgroundPreinitializer`. That's in a background thread, so
it isn't obviously going to slow down the startup, but if it causes
extra GC pressure, in particular that could be bad. See
https://github.com/spring-projects/spring-boot/issues/13423[spring-boot#1423]. It
makes quite a big difference (about 60ms). The data above already
include this improvement.

You can even start the `FuncApplication` in 12m heap without degrading
it. It runs in 8m but a bit slower, much slower in 6m, and fails to
start in 4m. GC is down to 3% of startup time in the "func" sample,
and 8% in "demo" (the fully-leaded `DemoApplication`).

With the `LazyInitBeanFactoryPostProcessor`:

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.bunc        ss   10  0.653 ± 0.154   s/op
MainBenchmark.func        ss   10  0.523 ± 0.132   s/op
```

In all 17 beans are not created in "bunc" on startup, compared to when
the lazy processor is not registered:

```
com.example.func.ReactorConfiguration
com.google.gson.Gson
com.google.gson.GsonBuilder
org.springframework.boot.autoconfigure.gson.GsonBuilderCustomizer
org.springframework.boot.autoconfigure.gson.GsonProperties
org.springframework.boot.autoconfigure.http.HttpEncodingProperties
org.springframework.boot.autoconfigure.http.HttpMessageConverters
org.springframework.boot.autoconfigure.reactor.core.ReactorCoreProperties
org.springframework.boot.web.client.RestTemplateBuilder
org.springframework.core.ReactiveAdapterRegistry
org.springframework.format.support.FormattingConversionService
org.springframework.http.converter.StringHttpMessageConverter
org.springframework.http.converter.json.GsonHttpMessageConverter
org.springframework.validation.Validator
org.springframework.web.reactive.accept.RequestedContentTypeResolver
org.springframework.web.reactive.config.WebFluxConfigurer
org.springframework.web.reactive.function.client.WebClient$Builder
```

Some of those might be needed if a JSON request was ever processed (it
won't be in this app). Some will never be needed
(e.g. `RestTemplateBuilder`).

== ConfigurationClassPostProcessor

We created a custom `ConfigurationClassPostProcessor` that only
processes classes that are present in spring.components. It doesn't
make much difference in a vanilla Spring Boot app. But if you use it
in an app that doesn't have any `@Configuration` it doesn't cost
anything (unlike the vanilla CCPP).  Spring Boot jars have
`spring.components` so this optimization doesn't affect the
functionality. Details:

```java

	public void enhanceConfigurationClasses(ConfigurableListableBeanFactory beanFactory) {
		...
		CandidateComponentsIndex index = CandidateComponentsIndexLoader.loadIndex(null);
		Set<String> components = index.getCandidateTypes("", Component.class.getName());
		for (String beanName : beanFactory.getBeanDefinitionNames()) {
			BeanDefinition beanDef = beanFactory.getBeanDefinition(beanName);
			if (!components.contains(beanDef.getBeanClassName())) {
				continue;
			}
            ...
```

== ConfigFileApplicationListener

See
https://github.com/spring-projects/spring-boot/issues/13436[Boot#13436].

`ConfigFileApplicationListener` creates a "description" of each
resource that it attempts to load. In a tight loop 40% of sampled time
goes to just creating the description (and 12% even when there is a
single config location). It turns out to be extremely inefficient
because of the use of `String.format` and `ResourceUtils.toURI` (both
are expensive). The description is only logged by default if the file
is found, so it isn't even used most of the time. I would recommend
just using the "location" instead which is always available and always
fairly descriptive of the resource, and costs nothing to compute.

The other main source of inefficiency is `ClassPathResource.exists()`
(25% sampled time). To fix that would be more involved - we'd probably
have to index the jars at build time or something. Might be worth
it. There's a workaround for users, though - if you know the locations
of the config files in the file system, you can skip searching the
classpath by specifying `spring.config.location` explicitly.

Result of optimizing `ConfigFileApplicationListener` description, and
setting `spring.config.location` explicitly (N.B. "func" is not
affected, which is expected):

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.boot        ss   10  1.074 ± 0.200   s/op
MainBenchmark.bunc        ss   10  0.631 ± 0.139   s/op
MainBenchmark.func        ss   10  0.571 ± 0.147   s/op
MainBenchmark.demo        ss   10  1.128 ± 0.209   s/op
MainBenchmark.manual      ss   10  1.014 ± 0.141   s/op
MainBenchmark.shared      ss   10  0.209 ± 0.067   s/op
```

Also, the `ApplicationConversionService` shows up in the flame graph
of "bunc" via `ConfigFileApplicationListener`, which uses it
indirectly through a `Binder`. The `Binder` in that listener in total
accounts for 1.5% of the startup time in "bunc", which seems
excessive. Adding the shared `ApplicationConversionService`
initialization to the `BackgroundPreinitializer` didn't help.

=== CloudFoundryVcapEnvironmentPostProcessor

See https://github.com/spring-projects/spring-boot/issues/13437[Boot#13437].

`CloudFoundryVcapEnvironmentPostProcessor` only needs to parse JSON if
it finds that the app is running in Cloud Foundry. But it always
instantiates a JSON parser in the class init, which is potentially
wasteful (2% of startup time in a really basic webflux app using
functional bean registration instead of autoconfig).

== Serializable Class Metadata

Using Kryo we were able to cache and re-load configuration class
metadata using a custom `MetadataReaderFactory`. The results are so
far inconclusive. The cost of serialization is close to the cost
of the ASM processing, so nothing is gained.

```
Benchmark               Mode  Cnt  Score   Error  Units
MainBenchmark.demo        ss   10  1.294 ± 0.095   s/op
MainBenchmark.shared      ss   10  0.264 ± 0.075   s/op
```

Flame graphs with `alloc=cpu`, with the cache:

image::images/flame_cached.svg[cpu_cached,width=50%]

Notice the large fraction of the samples in `GCTaskThread::run`
(19.47% of the total startup time). These graphs were generated using
the agent, so it captures the startup and only one application context
lifecycle, and with a higher sampling rate:

```
java 
```

The cached flamegraph doesn't look very different from the vanilla
one. The metadata in the cache probably contains all the warts of the
dynamically computed one, in terms of memory usage. It still has all
those ASM `Type` instances for example, so maybe we need a more
efficient representation of `AnnotationMetadata` and `ClassMetadata`
to take advantage of this kind of strategy.

Raw benchmarks for different metadata reading strategies:

```
Benchmark                     Mode  Cnt   Score    Error  Units
MetadataBenchmark.caching    thrpt   10  29.240 ± 13.408  ops/s
MetadataBenchmark.kryo       thrpt   10  65.272 ± 24.374  ops/s
MetadataBenchmark.reference  thrpt   10  48.779 ± 23.635  ops/s
MetadataBenchmark.simple     thrpt   10  27.544 ± 13.063  ops/s
```

The error bars are large but the averages are consistent between
runs. It's still warming up the JIT as it runs and it's not clear we
actually want it to be warm (it will never be warm on a cold
start). Key:

* "caching": used by Spring by default (and for `@ComponentScan` also in Spring Boot)

* "kryo": is the special cache of serialized metadata

* "reference": used by Spring Boot for `ConfigurationClassPostProcessor`, efficient reference-based cache of the ASM data

* "simple" is the raw ASM reader.

== Bean Creation Benchmarks

Create a `Bean` and inject a `Foo` into it:

```
Benchmark                       Mode  Cnt           Score           Error  Units
BeanCreationBenchmark.bare     thrpt    5  2863559599.756 ± 283985900.459  ops/s
BeanCreationBenchmark.cglib    thrpt    5      516603.359 ±      6503.198  ops/s
BeanCreationBenchmark.proxy    thrpt    5      565993.698 ±     53195.230  ops/s
BeanCreationBenchmark.reflect  thrpt    5     9968507.609 ±    133542.774  ops/s
BeanCreationBenchmark.simple   thrpt    5     4066914.320 ±    589505.416  ops/s
```

Key:

* "bare": just uses `new MyBean(foo)`

* "cglib": creates a CGLib proxy of `MyBean` and calls `setFoo(foo)`

* "proxy": same but for a JDK proxy

* "reflect": calls the constructor reflectively

* "simple": uses `DefaultListableBeanFactory.createBean()` to create a `MyBean` instance

Learnings:

* Proxies are slow - almost 20 times slower than vanilla reflection. CGLib isn't much different than JDK proxies (it used to be much slower).

* The `BeanFactory` is more than twice as slow as manually using reflection to create the bean. The difference might be in the use of `BeanInfo`, which always shows up on flame graphs.

* Reflection is 300 times slower than pure compiled bytecode.

A factor of 2 is almost not worth chasing at this level. A factor of
20 probably is. Ditto 300. So we should try to avoid proxies as much
as possible, and reflection. These results are probably independent of
the GC issues experienced by the full Spring Boot application startup.

== Java 10 Features

Java 10 is slower than Java 8 in general (so far at least), but it has
some features that might be useful to improve startup time.

One is Class Data Sharing:

```
$ CP=target/benchmarks.jar
$ java -Xshare:off -XX:+UseAppCDS -XX:DumpLoadedClassList=target/hello.lst -Ddemo.close=true -cp $CP com.example.func.FuncApplication
$ java -Xshare:dump -XX:+UseAppCDS -XX:SharedClassListFile=target/hello.lst -XX:SharedArchiveFile=target/hello.jsa -cp $CP com.example.func.FuncApplication
$ java -noverify -XX:TieredStopAtLevel=1 -Xshare:on -XX:+UseAppCDS -XX:SharedArchiveFile=target/hello.jsa -cp $CP com.example.func.FuncApplication
...
INFO: Netty started on port(s): 8080
Benchmark app started
Started HttpServer: 396ms
```

Compared with about 600ms without the CDS (with Java 8 and no CDS it is 500ms).

The other is Ahead of Time Compilation:

```
$ java -XX:DumpLoadedClassList=target/app.classlist -cp $CP com.example.func.FuncApplication
$ jaotc --output target/libDemo.so -J-cp -J$CP `cat target/app.classlist | sed -e 's,/,.,g'`
$ java -noverify -XX:TieredStopAtLevel=1 -XX:AOTLibrary=target/libDemo.so -cp $CP com.example.func.FuncApplication
Benchmark app started
Started HttpServer: 476ms
```

So better than 600ms, but not much faster than Java 8. One reason it
isn't a huge effect is that only the JDK classes are compiled (you
still need commercial features to compile application classes).